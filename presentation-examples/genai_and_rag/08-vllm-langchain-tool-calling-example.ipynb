{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[vLLM tool calling documentation](https://github.com/vllm-project/vllm/blob/main/docs/source/serving/openai_compatible_server.md#tool-calling-in-the-chat-completion-api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to executing this notebook, run the following command from the `presentation-examples/genai_and_rag` directory:\n",
    "```\n",
    "./vllm-tool-start.sh\n",
    "```\n",
    "Once the notebook has finished running, you may stop the vLLM server process by pressing Ctrl-C from the terminal that you ran the command in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# Database stub\n",
    "database = {\n",
    "    \"invoice_001\": {\n",
    "        \"supplier\": \"ABC Corp\",\n",
    "        \"amount\": 1500,\n",
    "        \"date\": \"2023-10-01\",\n",
    "        \"status\": \"Paid\",\n",
    "    },\n",
    "    \"invoice_002\": {\n",
    "        \"supplier\": \"XYZ Ltd\",\n",
    "        \"amount\": 2500,\n",
    "        \"date\": \"2023-10-05\",\n",
    "        \"status\": \"Pending\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# Function to fetch invoice information from the database\n",
    "@tool\n",
    "def fetch_invoice_info(invoice_id):\n",
    "    \"\"\"Fetch invoice information from the database.\"\"\"\n",
    "    return database.get(invoice_id, \"Invoice not found\")\n",
    "\n",
    "\n",
    "# Define our tools list\n",
    "tools = [fetch_invoice_info]\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"invoice_id\"],\n",
    "    template=\"What's the status of invoice id {invoice_id}?\",\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    api_key=\"abc1234\",\n",
    ")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "query = prompt_template.format(invoice_id=\"invoice_001\")\n",
    "\n",
    "# Call model w/ prompt and pass specific invoice_id\n",
    "response = llm_with_tools.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-cedd241362f1476eb6f98ff452c08805', 'function': {'arguments': '{\"invoice_id\": \"invoice_001\"}', 'name': 'fetch_invoice_info'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 178, 'total_tokens': 200, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None} id='run-aa87a2cf-46b5-4d85-ba2a-b0e16c05f70f-0' tool_calls=[{'name': 'fetch_invoice_info', 'args': {'invoice_id': 'invoice_001'}, 'id': 'chatcmpl-tool-cedd241362f1476eb6f98ff452c08805', 'type': 'tool_call'}] usage_metadata={'input_tokens': 178, 'output_tokens': 22, 'total_tokens': 200, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        \"\"\"You are provided with a tool to perform a database lookup when the user requests the status of an invoice with an invoice id. Perform the lookup and provide the status to the user in a clear, readable format. The status should be every field in the entry returned from the database on a separate line.\"\"\"\n",
    "    ),\n",
    "    HumanMessage(query),\n",
    "    response,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'fetch_invoice_info', 'args': {'invoice_id': 'invoice_001'}, 'id': 'chatcmpl-tool-cedd241362f1476eb6f98ff452c08805', 'type': 'tool_call'}\n",
      "content='{\"supplier\": \"ABC Corp\", \"amount\": 1500, \"date\": \"2023-10-01\", \"status\": \"Paid\"}' name='fetch_invoice_info' tool_call_id='chatcmpl-tool-cedd241362f1476eb6f98ff452c08805'\n"
     ]
    }
   ],
   "source": [
    "for tool_call in response.tool_calls:\n",
    "    selected_tool = {\"fetch_invoice_info\": fetch_invoice_info}[\n",
    "        tool_call[\"name\"].lower()\n",
    "    ]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are provided with a tool to perform a database lookup when the user requests the status of an invoice with an invoice id. Perform the lookup and provide the status to the user in a clear, readable format. The status should be every field in the entry returned from the database on a separate line.', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"What's the status of invoice id invoice_001?\", additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-cedd241362f1476eb6f98ff452c08805', 'function': {'arguments': '{\"invoice_id\": \"invoice_001\"}', 'name': 'fetch_invoice_info'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 178, 'total_tokens': 200, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-aa87a2cf-46b5-4d85-ba2a-b0e16c05f70f-0', tool_calls=[{'name': 'fetch_invoice_info', 'args': {'invoice_id': 'invoice_001'}, 'id': 'chatcmpl-tool-cedd241362f1476eb6f98ff452c08805', 'type': 'tool_call'}], usage_metadata={'input_tokens': 178, 'output_tokens': 22, 'total_tokens': 200, 'input_token_details': {}, 'output_token_details': {}}), ToolMessage(content='{\"supplier\": \"ABC Corp\", \"amount\": 1500, \"date\": \"2023-10-01\", \"status\": \"Paid\"}', name='fetch_invoice_info', tool_call_id='chatcmpl-tool-cedd241362f1476eb6f98ff452c08805')]\n"
     ]
    }
   ],
   "source": [
    "print(messages)\n",
    "messages.append(llm_with_tools.invoke(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are provided with a tool to perform a database lookup when the user requests the status of an invoice with an invoice id. Perform the lookup and provide the status to the user in a clear, readable format. The status should be every field in the entry returned from the database on a separate line.', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"What's the status of invoice id invoice_001?\", additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-cedd241362f1476eb6f98ff452c08805', 'function': {'arguments': '{\"invoice_id\": \"invoice_001\"}', 'name': 'fetch_invoice_info'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 178, 'total_tokens': 200, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-aa87a2cf-46b5-4d85-ba2a-b0e16c05f70f-0', tool_calls=[{'name': 'fetch_invoice_info', 'args': {'invoice_id': 'invoice_001'}, 'id': 'chatcmpl-tool-cedd241362f1476eb6f98ff452c08805', 'type': 'tool_call'}], usage_metadata={'input_tokens': 178, 'output_tokens': 22, 'total_tokens': 200, 'input_token_details': {}, 'output_token_details': {}}), ToolMessage(content='{\"supplier\": \"ABC Corp\", \"amount\": 1500, \"date\": \"2023-10-01\", \"status\": \"Paid\"}', name='fetch_invoice_info', tool_call_id='chatcmpl-tool-cedd241362f1476eb6f98ff452c08805'), AIMessage(content='This response indicates that the invoice with ID \"invoice_001\" is paid, and the details of the invoice are as follows:\\n\\n* Supplier: ABC Corp\\n* Amount: $1500\\n* Date: October 01, 2023\\n* Status: Paid\\n\\nThe response is in a clear and readable format, with each field on a separate line.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 302, 'total_tokens': 376, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-805d4211-3749-47e9-a233-fbf08c861d59-0', usage_metadata={'input_tokens': 302, 'output_tokens': 74, 'total_tokens': 376, 'input_token_details': {}, 'output_token_details': {}})]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to stop the vLLM server process from the terminal by pressing Ctrl-C. If you do not, then you will likely run out of GPU memory when executing the following notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
